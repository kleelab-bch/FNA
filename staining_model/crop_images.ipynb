{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T04:28:42.566049Z",
     "start_time": "2020-09-16T04:28:40.728624Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "YfIk2es3hJEd"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow_examples.models.pix2pix import pix2pix\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "tfds.disable_progress_bar()\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iYn4MdZnKCey"
   },
   "source": [
    "## Input Pipeline\n",
    "\n",
    "This tutorial trains a model to translate from images of horses, to images of zebras. You can find this dataset and similar ones [here](https://www.tensorflow.org/datasets/datasets#cycle_gan). \n",
    "\n",
    "As mentioned in the [paper](https://arxiv.org/abs/1703.10593), apply random jittering and mirroring to the training dataset. These are some of the image augmentation techniques that avoids overfitting.\n",
    "\n",
    "This is similar to what was done in [pix2pix](https://www.tensorflow.org/tutorials/generative/pix2pix#load_the_dataset)\n",
    "\n",
    "* In random jittering, the image is resized to `286 x 286` and then randomly cropped to `256 x 256`.\n",
    "* In random mirroring, the image is randomly flipped horizontally i.e left to right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T04:28:42.575440Z",
     "start_time": "2020-09-16T04:28:42.573502Z"
    }
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 1000\n",
    "BATCH_SIZE = 1\n",
    "IMAGE_WIDTH = 1024\n",
    "IMAGE_HEIGHT = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T04:28:42.584693Z",
     "start_time": "2020-09-16T04:28:42.582512Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "rwwYQpu9FzDu"
   },
   "outputs": [],
   "source": [
    "def resize(input_image, height, width):\n",
    "  input_image = tf.image.resize(input_image, [height, width],\n",
    "                                method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "\n",
    "  return input_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T04:29:31.026309Z",
     "start_time": "2020-09-16T04:29:31.018464Z"
    }
   },
   "outputs": [],
   "source": [
    "def crop_image_into_patches(image):\n",
    "    # crop 1944x2592x3 image into six 1024x1024x3 patches\n",
    "    #image=tf.expand_dims(image, axis=0)\n",
    "    patches = tf.image.extract_patches(images=image,\n",
    "                           sizes=[1,IMAGE_HEIGHT, IMAGE_WIDTH, 1],\n",
    "                           strides=[1,920, 784, 1],\n",
    "                           rates=[1, 1, 1, 1],\n",
    "                           padding='VALID')\n",
    "    reshaped_patches = tf.reshape(patches,[-1,IMAGE_HEIGHT,IMAGE_WIDTH,3])\n",
    "    return reshaped_patches\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PIGN6ouoQxt3",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Input Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T04:28:42.608364Z",
     "start_time": "2020-09-16T04:28:42.605561Z"
    }
   },
   "outputs": [],
   "source": [
    "root_image_path = '../../TfResearch/research/object_detection/dataset_tools/assets'\n",
    "train_root_image_path = '../../TfResearch/research/object_detection/dataset_tools/assets/images_train/'\n",
    "valid_root_image_path = '../../TfResearch/research/object_detection/dataset_tools/assets/images_valid/'\n",
    "test_root_image_path = '../../TfResearch/research/object_detection/dataset_tools/assets/images_test/'\n",
    "\n",
    "root_mask_path = '../assets/all-patients-stained'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T04:28:43.223052Z",
     "start_time": "2020-09-16T04:28:43.217277Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_image(image_file):\n",
    "    image = tf.io.read_file(image_file)\n",
    "    image = tf.image.decode_png(image, channels=3)\n",
    "    image = tf.cast(image, tf.float32)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T04:28:46.904902Z",
     "start_time": "2020-09-16T04:28:43.564207Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "SQHmYSmk8b4b",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "stained_train_dataset = tf.data.Dataset.list_files(root_mask_path+'/masks_train/*.png')\n",
    "stained_valid_dataset = tf.data.Dataset.list_files(root_mask_path+'/masks_valid/*.png')\n",
    "\n",
    "stained_dataset = stained_train_dataset.concatenate(stained_valid_dataset)\n",
    "\n",
    "stained_dataset = stained_dataset.map(load_image, num_parallel_calls=tf.data.experimental.AUTOTUNE).cache().shuffle(BUFFER_SIZE).batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T04:28:47.255611Z",
     "start_time": "2020-09-16T04:28:46.913809Z"
    }
   },
   "outputs": [],
   "source": [
    "unstained_train_dataset_names = tf.data.Dataset.list_files(train_root_image_path + '*.png')\n",
    "unstained_valid_dataset_names = tf.data.Dataset.list_files(valid_root_image_path + '*.png')\n",
    "unstained_test_dataset_names = tf.data.Dataset.list_files(test_root_image_path + '*.png')\n",
    "\n",
    "unstained_dataset = unstained_train_dataset_names.concatenate(unstained_valid_dataset_names)\n",
    "unstained_dataset = unstained_dataset.concatenate(unstained_test_dataset_names)\n",
    "\n",
    "unstained_dataset = unstained_dataset.map(load_image, num_parallel_calls=tf.data.experimental.AUTOTUNE).cache().shuffle(BUFFER_SIZE).batch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Whole Image into Patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T04:29:33.446479Z",
     "start_time": "2020-09-16T04:29:33.386223Z"
    }
   },
   "outputs": [],
   "source": [
    "cropped_stained_dataset = stained_dataset.map(crop_image_into_patches, num_parallel_calls=tf.data.experimental.AUTOTUNE).cache().shuffle(BUFFER_SIZE).batch(1)\n",
    "cropped_unstained_dataset = unstained_dataset.map(crop_image_into_patches, num_parallel_calls=tf.data.experimental.AUTOTUNE).cache().shuffle(BUFFER_SIZE).batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T04:40:35.676518Z",
     "start_time": "2020-09-16T04:40:35.671823Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "RmdVsmvhPxyy"
   },
   "outputs": [],
   "source": [
    "def save_image(input_image, save_path):\n",
    "    cv2.imwrite(save_path, cv2.cvtColor(input_image.numpy(), cv2.COLOR_RGB2BGR))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T04:40:39.761469Z",
     "start_time": "2020-09-16T04:40:38.865794Z"
    }
   },
   "outputs": [],
   "source": [
    "generate_path_unstained = 'generated/training_unstained/'\n",
    "generate_path_stained = 'generated/training_stained/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T04:45:20.503903Z",
     "start_time": "2020-09-16T04:41:37.368496Z"
    }
   },
   "outputs": [],
   "source": [
    "image_counter = 0\n",
    "for image in cropped_unstained_dataset:\n",
    "    image = image[0]\n",
    "    for patch_num in range(image.shape[0]):\n",
    "        save_image(image[patch_num], generate_path_unstained + f'{image_counter}_{patch_num}.png')\n",
    "    image_counter = image_counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T04:47:58.174218Z",
     "start_time": "2020-09-16T04:45:20.583742Z"
    }
   },
   "outputs": [],
   "source": [
    "image_counter = 0\n",
    "for image in cropped_stained_dataset:\n",
    "    image = image[0]\n",
    "    for patch_num in range(image.shape[0]):\n",
    "        save_image(image[patch_num], generate_path_stained + f'{image_counter}_{patch_num}.png')\n",
    "    image_counter = image_counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow-2] *",
   "language": "python",
   "name": "conda-env-tensorflow-2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
